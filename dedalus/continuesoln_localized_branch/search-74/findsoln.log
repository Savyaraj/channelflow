f(u, N, dt, f_u, flags, dt) : Computing G(x)
f(u, N, dt, f_u, flags, dt) : 
========================================================
Newton iteration number 0
Current state of Newton iteration:
   fcount_newton   == 1
   fcount_optimiza == 0
   L2Norm(x)       == 0.0223697
   L2Norm(dxN)     == 0
   L2Norm(dxOpt)   == 0
   L2Dist(x,x0)    == 0
gx == L2Norm(G(x)) : 
   initial  gx == 3.37265e-08
   previous gx == 3.37265e-08
   current  gx == 3.37265e-08
rx == 1/2 L2Norm2(G(x)) : 
   initial  rx == 5.6874e-16
   previous rx == 5.6874e-16
   current  rx == 5.6874e-16
         delta == 0.01
Newt,GMRES == 0,0, f(u, N, dt, f_u, flags, dt) :  res == 0.988464
Newt,GMRES == 0,1, f(u, N, dt, f_u, flags, dt) :  res == 0.418046
Newt,GMRES == 0,2, f(u, N, dt, f_u, flags, dt) :  res == 0.413091
Newt,GMRES == 0,3, f(u, N, dt, f_u, flags, dt) :  res == 0.241093
Newt,GMRES == 0,4, f(u, N, dt, f_u, flags, dt) :  res == 0.0663929
GMRES converged. Breaking.
Hookstep optimization is currently not implemented with Arclength Continuation.
Optimized Newton algorithm with AC: Computing residual to check convergence...f(u, N, dt, f_u, flags, dt) : : gx = 2.82687e-09 < 3.37265e-08
The residual is decreasing if we take this AC-Newton step.

Taking best step and continuing Newton iteration.
L2Norm(G(x)) == 2.82687e-09
rx           == 3.99559e-18
L2Norm(dxN)  == 2.68504e-05
L2Norm(dxOpt)== 2.68504e-05
========================================================
Newton iteration number 1
Current state of Newton iteration:
   fcount_newton   == 6
   fcount_optimiza == 1
   L2Norm(x)       == 0.0223612
   L2Norm(dxN)     == 2.68504e-05
   L2Norm(dxOpt)   == 2.68504e-05
   L2Dist(x,x0)    == 2.68505e-05
gx == L2Norm(G(x)) : 
   initial  gx == 3.37265e-08
   previous gx == 3.37265e-08
   current  gx == 2.82687e-09
rx == 1/2 L2Norm2(G(x)) : 
   initial  rx == 5.6874e-16
   previous rx == 5.6874e-16
   current  rx == 3.99559e-18
         delta == 0.01
Newton search converged. Breaking.
L2Norm(G(x)) == 2.82687e-09 < epsSearch == 1e-08
